{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1250ad0c-a37f-4f6d-a396-f9243fc6eef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import io\n",
    "import time\n",
    "\n",
    "files = ['166.8 M  333.7 M  hdfs://main:9000/double.csv',\n",
    " '166.8 M  166.8 M  hdfs://main:9000/single.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c163342-f283-4578-9f51-2154c23b9eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 1: HDFS Deployment and Data Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b720ebc7-fbbb-4af0-9fa1-bbf29aa6d1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv already downloaded\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"hdma-wi-2021.csv\"):\n",
    "    !wget https://pages.cs.wisc.edu/~harter/cs639/data/hdma-wi-2021.csv\n",
    "else:\n",
    "    print(\"csv already downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65d233cc-7bd1-4958-a815-e88df780bbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = !hdfs dfs -du -h hdfs://main:9000/\n",
    "\n",
    "if result != files:\n",
    "    !hdfs dfs -D dfs.block.size=1048576 -D dfs.replication=1 -cp hdma-wi-2021.csv hdfs://main:9000/single.csv\n",
    "    !hdfs dfs -D dfs.block.size=1048576 -D dfs.replication=2 -cp hdma-wi-2021.csv hdfs://main:9000/double.csv\n",
    "else:\n",
    "    print(\"files already copied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5224fe5b-2f21-41b0-8e11-b5e9ff3f1206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166.8 M  333.7 M  hdfs://main:9000/double.csv\n",
      "166.8 M  166.8 M  hdfs://main:9000/single.csv\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -du -h hdfs://main:9000/\n",
    "# expected output\n",
    "# 166.8 M  333.7 M  hdfs://main:9000/double.csv\n",
    "# 166.8 M  166.8 M  hdfs://main:9000/single.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22532026-41f8-486a-b8d1-d9837a1dccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 2: Block Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12f51dff-eb7a-4fb1-8f6e-4bb7c9fc2099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'http://e26cd7a84cc9:9864/webhdfs/v1/single.csv': 86,\n",
       " 'http://9bf8706a3306:9864/webhdfs/v1/single.csv': 81}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks = {}\n",
    "blockSize = 1048576\n",
    "blockNumber = 0\n",
    "for i in range(167):\n",
    "    url = f\"http://main:9870/webhdfs/v1/single.csv/?op=OPEN&length=1000&offset={blockNumber}\"\n",
    "    resp = requests.get(url, allow_redirects=False)\n",
    "    resp.raise_for_status\n",
    "    location = resp.headers[\"Location\"][:46]\n",
    "    if location in blocks:\n",
    "        blocks[location] +=1\n",
    "    else:\n",
    "        blocks[location] = 1\n",
    "    blockNumber+=blockSize\n",
    "        \n",
    "blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1e1e904-4237-43cd-a1a6-53e82f3ca305",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 3: Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60129ae2-4489-4e67-8fd7-8772e1b7ff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class hdfsFile(io.RawIOBase):\n",
    "    def __init__(self, path):\n",
    "        url = f\"http://main:9870/webhdfs/v1/{path}/?op=LISTSTATUS\"\n",
    "        resp = requests.get(url, allow_redirects=False)\n",
    "        json = resp.json()\n",
    "        self.path = path\n",
    "        self.offset = 0\n",
    "        self.length = json['FileStatuses']['FileStatus'][0]['length']\n",
    "\n",
    "    def readable(self):\n",
    "        return True\n",
    "\n",
    "    def readinto(self, b):\n",
    "        if self.offset < self.length:\n",
    "            url = f\"http://main:9870/webhdfs/v1/{self.path}/?op=OPEN&length={len(b)}&offset={self.offset}\"\n",
    "            resp = requests.get(url, allow_redirects=True)\n",
    "            if(resp.status_code == 403):\n",
    "                b[0:1] = bytes(\"\\n\", \"utf-8\")\n",
    "                self.offset += len(b)\n",
    "                return 1\n",
    "            else:\n",
    "                b[0:len(resp.content)] = bytes(resp.content)\n",
    "                self.offset += len(b)\n",
    "                return len(resp.content)\n",
    "        else:\n",
    "            return 0 # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9308d35-f63e-4179-ac57-dc2d855d0c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts from single.csv with 1MB buffer size\n",
      "Single Family: 444874\n",
      "Multi Family: 2493\n",
      "Seconds: 13.823347568511963\n",
      "\n",
      "Counts from single.csv with 65.536KB buffer size\n",
      "Single Family: 444874\n",
      "Multi Family: 2493\n",
      "Seconds: 49.031872272491455\n"
     ]
    }
   ],
   "source": [
    "Single_Family = 0 \n",
    "Multi_Family  = 0\n",
    "t0 = time.time()\n",
    "for line in io.BufferedReader(hdfsFile(\"single.csv\"), buffer_size=1048576):\n",
    "    line = str(line, \"utf-8\")\n",
    "    if \"Single Family\" in line:\n",
    "        Single_Family+=1\n",
    "    if \"Multifamily\" in line:\n",
    "        Multi_Family+=1\n",
    "t1 = time.time()\n",
    "\n",
    "print(\"Counts from single.csv with 1MB buffer size\")\n",
    "print(\"Single Family: \" + str(Single_Family))\n",
    "print(\"Multi Family: \" + str(Multi_Family))\n",
    "print(\"Seconds: \" + str(t1-t0))\n",
    "print()\n",
    "\n",
    "Single_Family2 = 0 \n",
    "Multi_Family2  = 0\n",
    "t2 = time.time()\n",
    "for line in io.BufferedReader(hdfsFile(\"single.csv\"), buffer_size=65536):\n",
    "    line = str(line, \"utf-8\")\n",
    "    if \"Single Family\" in line:\n",
    "        Single_Family2+=1\n",
    "    if \"Multifamily\" in line:\n",
    "        Multi_Family2+=1\n",
    "t3 = time.time()\n",
    "\n",
    "\n",
    "print(\"Counts from single.csv with 65.536KB buffer size\")\n",
    "print(\"Single Family: \" + str(Single_Family2))\n",
    "print(\"Multi Family: \" + str(Multi_Family2))\n",
    "print(\"Seconds: \" + str(t3-t2))\n",
    "\n",
    "# Counts from single.csv\n",
    "# Single Family: 444874\n",
    "# Multi Family: 2493\n",
    "# Seconds: 24.33926248550415"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "117367d9-090e-43dd-b326-6f91aae98352",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 4: Disaster Strikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c63e583-7c75-4ac6-8d9b-0336d0cba32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Configured Capacity: 51642105856 (48.10 GB)',\n",
       " 'Present Capacity: 23979203708 (22.33 GB)',\n",
       " 'DFS Remaining: 23450218496 (21.84 GB)',\n",
       " 'DFS Used: 528985212 (504.48 MB)',\n",
       " 'DFS Used%: 2.21%',\n",
       " 'Replicated Blocks:',\n",
       " '\\tUnder replicated blocks: 0',\n",
       " '\\tBlocks with corrupt replicas: 0',\n",
       " '\\tMissing blocks: 0',\n",
       " '\\tMissing blocks (with replication factor 1): 0',\n",
       " '\\tLow redundancy blocks with highest priority to recover: 0',\n",
       " '\\tPending deletion blocks: 0',\n",
       " 'Erasure Coded Block Groups: ',\n",
       " '\\tLow redundancy block groups: 0',\n",
       " '\\tBlock groups with corrupt internal blocks: 0',\n",
       " '\\tMissing block groups: 0',\n",
       " '\\tLow redundancy blocks with highest priority to recover: 0',\n",
       " '\\tPending deletion blocks: 0',\n",
       " '',\n",
       " '-------------------------------------------------',\n",
       " 'Live datanodes (1):',\n",
       " '',\n",
       " 'Name: 172.18.0.4:9866 (project-3-nateproject3-worker-2.cs544net)',\n",
       " 'Hostname: 9bf8706a3306',\n",
       " 'Decommission Status : Normal',\n",
       " 'Configured Capacity: 25821052928 (24.05 GB)',\n",
       " 'DFS Used: 261765966 (249.64 MB)',\n",
       " 'Non DFS Used: 13817414834 (12.87 GB)',\n",
       " 'DFS Remaining: 11725094912 (10.92 GB)',\n",
       " 'DFS Used%: 1.01%',\n",
       " 'DFS Remaining%: 45.41%',\n",
       " 'Configured Cache Capacity: 0 (0 B)',\n",
       " 'Cache Used: 0 (0 B)',\n",
       " 'Cache Remaining: 0 (0 B)',\n",
       " 'Cache Used%: 100.00%',\n",
       " 'Cache Remaining%: 0.00%',\n",
       " 'Xceivers: 1',\n",
       " 'Last contact: Fri Mar 17 20:54:33 GMT 2023',\n",
       " 'Last Block Report: Fri Mar 17 20:49:06 GMT 2023',\n",
       " 'Num of Blocks: 248',\n",
       " '',\n",
       " '',\n",
       " 'Dead datanodes (1):',\n",
       " '',\n",
       " 'Name: 172.18.0.3:9866 (172.18.0.3)',\n",
       " 'Hostname: e26cd7a84cc9',\n",
       " 'Decommission Status : Normal',\n",
       " 'Configured Capacity: 25821052928 (24.05 GB)',\n",
       " 'DFS Used: 267219246 (254.84 MB)',\n",
       " 'Non DFS Used: 13811932882 (12.86 GB)',\n",
       " 'DFS Remaining: 11725123584 (10.92 GB)',\n",
       " 'DFS Used%: 1.03%',\n",
       " 'DFS Remaining%: 45.41%',\n",
       " 'Configured Cache Capacity: 0 (0 B)',\n",
       " 'Cache Used: 0 (0 B)',\n",
       " 'Cache Remaining: 0 (0 B)',\n",
       " 'Cache Used%: 100.00%',\n",
       " 'Cache Remaining%: 0.00%',\n",
       " 'Xceivers: 1',\n",
       " 'Last contact: Fri Mar 17 20:52:48 GMT 2023',\n",
       " 'Last Block Report: Fri Mar 17 20:49:06 GMT 2023',\n",
       " 'Num of Blocks: 253',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wait for worker datanode to die\n",
    "report = !hdfs dfsadmin -fs hdfs://main:9000/ -report\n",
    "while(\"Dead datanodes\" not in str(report)):\n",
    "      time.sleep(20)\n",
    "      report = !hdfs dfsadmin -fs hdfs://main:9000/ -report\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cee9b245-8661-4000-a2be-8bab50eb063a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts from double.csv with 1MB buffer size\n",
      "Single Family: 444874\n",
      "Multi Family: 2493\n",
      "\n",
      "Counts from single.csv with 1MB buffer size\n",
      "Single Family: 215999\n",
      "Multi Family: 1170\n"
     ]
    }
   ],
   "source": [
    "#if ConnectionError occurs rerun this cell\n",
    "\n",
    "Single_Family = 0 \n",
    "Multi_Family  = 0\n",
    "\n",
    "for line in io.BufferedReader(hdfsFile(\"double.csv\"), buffer_size=1048576):\n",
    "    line = str(line, \"utf-8\")\n",
    "    if \"Single Family\" in line:\n",
    "        Single_Family+=1\n",
    "    if \"Multifamily\" in line:\n",
    "        Multi_Family+=1\n",
    "\n",
    "\n",
    "print(\"Counts from double.csv with 1MB buffer size\")\n",
    "print(\"Single Family: \" + str(Single_Family))\n",
    "print(\"Multi Family: \" + str(Multi_Family))\n",
    "print()\n",
    "\n",
    "Single_Family = 0 \n",
    "Multi_Family  = 0\n",
    "\n",
    "for line in io.BufferedReader(hdfsFile(\"single.csv\"), buffer_size=1048576):\n",
    "    line = str(line, \"utf-8\")\n",
    "    if \"Single Family\" in line:\n",
    "        Single_Family+=1\n",
    "    if \"Multifamily\" in line:\n",
    "        Multi_Family+=1\n",
    "\n",
    "\n",
    "print(\"Counts from single.csv with 1MB buffer size\")\n",
    "print(\"Single Family: \" + str(Single_Family))\n",
    "print(\"Multi Family: \" + str(Multi_Family))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13e2de1-a179-4310-b107-54fa340882da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
